---
title: "STA380 Exercise 2"
output: html_document
---
library(knitr)
knit2html('./STA380Assignment2.Rmd')


#Flights at ABIA
```{r, echo= FALSE}
AirportInfo = read.csv("ABIA.csv", header=TRUE)
attach(AirportInfo)
names(AirportInfo)
library(mosaic)
library(foreach)

AirportInfo$Austin <- ifelse(AirportInfo$Origin == "AUS", "Yes", NA)

names(AirportInfo)




Cancel<-AirportInfo[,c(2,22,30)]

names(Cancel)
NoNA <- na.omit(Cancel) 
names(NoNA)

ave.Depdelay <- aggregate(NoNA$Cancelled, by=list(NoNA$Month),sum)

plot(ave.Depdelay,xlab="Month",ylab="Cancellations",main= "Flights from Austin: Cancellations by month")
```

- March had the most flights cancelled.

```{r, echo=FALSE}
library(Hmisc)
names(AirportInfo)
par(mfrow=c(1,2))

Cancellations<-AirportInfo[,c(18,22,30)]
names(Cancellations)
DestCancelled <- na.omit(Cancellations) 
DestCancel <- aggregate(DestCancelled$Cancelled, by=list(DestCancelled$Dest), sum)


plot(DestCancel,xlab="Destination",ylab="Cancellations",main= "Flights from Austin:Cancellations by Destination", las=2)

Flights <- AirportInfo[,c(18,30)]
FlightsToDest <- na.omit(Flights) 
FlightsToDest$Austin <- 1
DestFlights<- aggregate(FlightsToDest$Austin, by=list(FlightsToDest$Dest), sum)
DestFlights$x
plot(DestFlights,xlab="Destination",ylab="Total Flights",main= "Flights from Austin: Total flights to each Destination", las=2)
```

- This shows the number of cancellations of flights from Austin to various airports. Dallas has by far the most cancellations, however it also had the most flights.



```{r, echo=FALSE}
par(mfrow=c(1,1))
DestCancel$Total <- DestFlights$x
DestCancel$Percent <- (DestCancel$x/DestCancel$Total)*100

plot(DestCancel$Group.1, DestCancel$Percent,xlab=" Destination ",ylab="Cancellation Percentage",main= "Cancellation percentage of flights from Austin by Destination",  las=3)
```

- This shows the percent of flights to each destination that are cancelled.

```{r, echo=FALSE}


Cancelled<-AirportInfo[,c(4,22,30)]
CancelledFlights <- na.omit(Cancelled)
names(CancelledFlights)

CountCancells <- aggregate(Cancelled$Cancelled, by=list(Cancelled$DayOfWeek), sum)

plot(CountCancells ,xlab="Day of Week ",ylab="Cancellations",main= "Cancellations by Day of Week for flights from Austin", las=2)
```

- This shows the total cancellations by day of the week on flights from Austin. Tuesday had the most cancellations by roughly 70 cancellations over the course of the year.

```{r, echo=FALSE}

names(AirportInfo)
CancelledByAirline<-AirportInfo[,c(9,22,10,30)]
CancelledFlight <- na.omit(CancelledByAirline)
CancelCarrier <- aggregate(CancelledFlight$Cancelled, by=list(CancelledFlight$UniqueCarrier), sum)

FlightsByAirline<-AirportInfo[,c(9,30)]
Flight <- na.omit(FlightsByAirline)
Flight$Austin <- 1
TotalFlights<- aggregate(Flight$Austin, by=list(Flight$UniqueCarrier), sum)

par(mfrow=c(1,2))

plot(CancelCarrier ,xlab="Airline ",ylab="Cancellations",main= "Cancellations by Airlines of flights from Austin", col= "red", las=3)

plot(TotalFlights ,xlab="Airline ",ylab="TotalFlights",main= "Flights by Airlines of flights from Austin", col= "red", las=3)





```

- This shows cancellations on flights from Austin by airline next to the total number of flights from Austin by each airline in 2008.
```{r, echo=FALSE}
par(mfrow=c(1,1))
CancelCarrier$Total = TotalFlights$x
CancelCarrier$Percent <- (CancelCarrier$x/CancelCarrier$Total)*100

plot(CancelCarrier$Group.1, CancelCarrier$Percent,xlab="Airline ",ylab="Cancelleation Percentage",main= "Cancellation percentage of flights from Austin by Airline",  las=3)

```

- This shows the percent of flights cancelled by airline for flights from Austin. While American airlines cancelled the most flights in 2008, American Eagle cancelled the largest percentage of its flights.

#Author Attribution
- I used Naive Bayes and Random Forest to try to determine the authors of each article.
```{r}
library(tm)
library(e1071)
library(rpart)
library(ggplot2)
library(caret)

#reader function
readerPlain = function(fname){
  readPlain(elem=list(content=readLines(fname)), id=fname, language='en') }
```

##Training Corpus
```{r}
author_dirs = Sys.glob('./ReutersC50/C50train/*')
file_list = NULL
train_labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=23)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  train_labels = append(train_labels, rep(author_name, length(files_to_add)))
}

all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))


train_corpus = Corpus(VectorSource(all_docs))
names(train_corpus) = file_list


train_corpus = tm_map(train_corpus, content_transformer(tolower)) 
train_corpus = tm_map(train_corpus, content_transformer(removeNumbers)) 
train_corpus = tm_map(train_corpus, content_transformer(removePunctuation)) 
train_corpus = tm_map(train_corpus, content_transformer(stripWhitespace)) 
train_corpus = tm_map(train_corpus, content_transformer(removeWords), stopwords("SMART"))

```
- Here I'm putting the training articles into one corpus and cleaning/ tokenizing similarly to the example in class.

- Next comes making a data matrix and removing sparse terms.
```{r}
DTM_train = DocumentTermMatrix(train_corpus)
DTM_train = removeSparseTerms(DTM_train, 0.95)

```


##Testing Corpus
```{r}
author_dirs = Sys.glob('./ReutersC50/C50test/*')
file_list = NULL
test_labels = NULL
for(author in author_dirs) {
  author_name = substring(author, first=22)
  files_to_add = Sys.glob(paste0(author, '/*.txt'))
  file_list = append(file_list, files_to_add)
  test_labels = append(test_labels, rep(author_name, length(files_to_add)))
}


all_docs = lapply(file_list, readerPlain) 
names(all_docs) = file_list
names(all_docs) = sub('.txt', '', names(all_docs))


test_corpus = Corpus(VectorSource(all_docs))
names(test_corpus) = file_list

test_corpus = tm_map(test_corpus, content_transformer(tolower)) 
test_corpus = tm_map(test_corpus, content_transformer(removeNumbers)) 
test_corpus = tm_map(test_corpus, content_transformer(removePunctuation)) 
test_corpus = tm_map(test_corpus, content_transformer(stripWhitespace)) 
test_corpus = tm_map(test_corpus, content_transformer(removeWords), stopwords("SMART"))

```
- The process for creating the testing corpus is similar to the training corpus to this point.

```{r}


reuters_dict = dimnames(DTM_train)[[2]]


DTM_test = DocumentTermMatrix(test_corpus, list(dictionary=reuters_dict))
DTM_test = removeSparseTerms(DTM_test, 0.95)


DTM_train_df = as.data.frame(inspect(DTM_train))

DTM_test_df = as.data.frame(inspect(DTM_test))

```
- This helps deal with words that were not seen in data set by just focusing on the 641 words that made it from the training data and sparsity. 

### Naive Bayes
```{r}


model_NB = naiveBayes(x=DTM_train_df, y=as.factor(train_labels), laplace=2)

pred_NB = predict(model_NB, DTM_test_df)


table_NB = as.data.frame(table(pred_NB,test_labels))


conf_NB = confusionMatrix(table(pred_NB,test_labels))

conf_NB_df = as.data.frame(conf_NB$byClass)
conf_NB_df[order(-conf_NB_df$Sensitivity),c(1,2,8)]

```
- This creates runs the Naive Bayes' model and creates a confusion matrix of results. This model has an accuracy score of 27.96%. Authors such as Peter Humphrey and Roger Fillion were predicted fairly accurately while the model failed to predict Schuettler, Macartney,Dicke,Eelyn and Kazer.

### Random Forest
- This method makes sense since it allows for many simulations of different combinations of words to try to predict the author. 
```{r}


set.seed(1)
DTM_test = as.matrix(DTM_test)
DTM_train = as.matrix(DTM_train)

xx <- data.frame(DTM_test[,intersect(colnames(DTM_test), colnames(DTM_train))])
yy <- read.table(textConnection(""), col.names = colnames(DTM_train), colClasses = "integer")

```
- This makes sure that both the test set has all of the same words as the training set.

```{r}

library(plyr)
DTM_test_clean = rbind.fill(xx, yy)

DTM_test_df = as.data.frame(DTM_test_clean)

library(randomForest)
model_RF = randomForest(x=DTM_train_df, y=as.factor(train_labels), mtry=4, ntree=350)
pred_RF = predict(model_RF, data=DTM_test_clean)

table_RF = as.data.frame(table(pred_RF,test_labels))


conf_RF = confusionMatrix(table(pred_RF,test_labels))

conf_RF$overall
conf_RF_df = as.data.frame(conf_RF$byClass)
conf_RF_df[order(-conf_RF_df$Sensitivity),c(1,2,8)]


```
- I ran a randomForest model of  four words on 350 trees. The model had an accuracy score of 74%, which is much better than Naive Bayes. 12 authors had a sensitivity score of .9 or better which is much better than Naive Bayes.



#Association Rule Mining
```{r}
detach(package:tm,unload=TRUE)
library(arules)

# Read in transactions
Transactions<- read.transactions("./groceries.txt",format = c("basket"),sep=",")
Carts <- apriori(Transactions, parameter=list(support=.01, confidence=.4, maxlen=5))
inspect(Carts)



```

- A support of .01 works here since there are so many possible items for a cart, if a set of items appear in 1% of the carts it's a pretty high number. Confidence of .4 gives a larger list than a higher confidence number, but I will subset a bit to try to see if I can get rules with higher confidence.

```{r}
inspect(subset(Carts, subset=confidence >.5 & lift > 2.5))

```

- If a cart contains root vegetables and fruit, it'll  contain some more vegetables. This makes sense to me as those who buy fruits and vegetables should be more likely to buy more fruits and vegetables. What's interesting is when we add rolls/buns with root vegetables buys other vegetables. But that could be for sandwiches or burgers and the vegetables could be placed on top.

```{r}
inspect(subset(Carts, subset=confidence > 0.5 & support > .015))
```
- If a cart containts tropical fruti/vegetables and yogurt it will contain whole milk. This makes sense as carts containing a dairy product should intuitively contain more dairy products. 

```{r}
Carts <- apriori(Transactions, parameter=list(support=.001, confidence=.4, maxlen=5))
carts.sorted <- sort(Carts, by="lift")
inspect(carts.sorted)



```
- I also want to examine which rules may have  high lift but are not showing up due to low support. This way rules in which the lift value is particularly high can be noted


```{r}
inspect(subset(carts.sorted, subset=lift>6))
```

- Those who by bottled beer and other liqour appear much more likely to buy wine than other customers, but just because a cart has beer and liquor doesn't mean it will also contain wine. 

```{r}
inspect(subset(carts.sorted, subset= confidence > .5 & lift>10))
```

- Instant food products and sodas on the other hand are very likely to be paired by hamburger meat, and buy burger meat at with a much higher frequency than the general population.
- Similarly those who buy ham and cheese frequently purchase white bread and are much more likely than the general population.
- 90% of the time a cart has liquor and red/blush wine it contains bottled beer. This is significantly higher than the 40% confidence than the rule about those buy liquor and beer then buy wine. 
